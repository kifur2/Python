{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "139878_Cudak_Jakub_Deep_Lab_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMMXLENOd7V-"
      },
      "source": [
        "# Wstęp do Sztucznej Inteligencji - rok akademicki 2021/2022\n",
        "\n",
        "Przed rozpoczęciem pracy z notatnikiem zmień jego nazwę zgodnie z wzorem: `NrAlbumu_Nazwisko_Imie_PoprzedniaNazwa`.\n",
        "\n",
        "Przed wysłaniem notatnika upewnij się, że rozwiązałeś wszystkie zadania/ćwiczenia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZZF68t-kiQ8"
      },
      "source": [
        "## Biblioteka Keras. Sieci konwolucyjne.\n",
        "Zapoznaj się z treścią niniejszego notatnika czytając i wykonując go komórka po komórce. Wykonaj napotkane zadania/ćwiczenia.\n",
        "\n",
        "Keras: https://keras.io/\n",
        "\n",
        "TensorFlow: https://www.tensorflow.org/\n",
        "\n",
        "__Uwaga!__\n",
        "Trenowanie przykładowych sieci w tym notatniku jest wymagające obliczeniowo. W razie problemów, skorzystaj z załączonych pretrenowanych modeli (pliki \\*.hdf5)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6D03-d0-aqp"
      },
      "source": [
        "### Sprawdź swoją konfigurację"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQbPKbDh-lU0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwgxhLoJ1uGq"
      },
      "source": [
        "## Baza MNIST\n",
        "Baza MNIST zawiera zbiór trenujący składający się z 60,000 przykładów skanów ręcznie pisanych cyfr od 0 do 9 (problem klasyfikacyjny z 10 klasami). \n",
        "\n",
        "Zbiór testowy zawiera 10,000 przykładów.\n",
        "\n",
        "Każdy obraz ma rozmiar 28x28 pikseli. Stanowią one 28 * 28 = 784 wejść do sieci.\n",
        "\n",
        "W zagadnieniach rozpoznawania obrazów baza MNIST pełni rolę swoistego problemu `Hello world`.\n",
        "\n",
        "Przeczytaj więcej o bazie MNIST:\n",
        "\n",
        "http://yann.lecun.com/exdb/mnist/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTpCaibN1Ccp"
      },
      "source": [
        "### Pobranie bazy MNIST\n",
        "\n",
        "Baza MNIST może być pobrana w wersji binarnej bezpośrednio ze strony\n",
        "http://yann.lecun.com/exdb/mnist/\n",
        "\n",
        "W formie plików \\*.csv baza MNIST jest dostępna na stronie\n",
        "\n",
        "https://pjreddie.com/projects/mnist-in-csv/\n",
        "\n",
        "Najwygodniej jednak użyć importu bazy MNIST z wykorzystaniem biblioteki Keras. Przy pierwszym imporcie baza ta zostanie pobrana automatycznie (ok. 12MB). Umieszczona zostanie w katalogu `~/.keras/datasets/mnist.pkl.gz`.\n",
        "\n",
        "Poniżej znajduje się przykładowy kod wczytujący dane trenujące i testowe, oraz wyświetlający kilka przykładowych obrazów."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFbsL_1tARI_"
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n",
        "print('xtrain.shape',xtrain.shape)\n",
        "print('ytrain.shape',ytrain.shape)\n",
        "print('xtest.shape',xtest.shape)\n",
        "print('ytest.shape',ytest.shape)\n",
        "\n",
        "#wyswietlenie pierwszego przykladu\n",
        "plt.imshow(xtest[0,:,:], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "#Wyswietlenie kilku pierwszych przykladow\n",
        "rows = 8\n",
        "cols = 10\n",
        "counter = 0\n",
        "\n",
        "images = None\n",
        "\n",
        "for i in range(rows):\n",
        "    current_row = None\n",
        "    for j in range(cols):\n",
        "        im = xtest[counter,:,:]\n",
        "        counter = counter + 1\n",
        "        if current_row is None:\n",
        "            current_row = im\n",
        "        else:\n",
        "            current_row = np.hstack((current_row, im))\n",
        "    if images is None:\n",
        "        images = current_row\n",
        "    else:\n",
        "        images = np.vstack((images, current_row))\n",
        "        \n",
        "plt.figure()\n",
        "plt.imshow(images, cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx6b2MiJ2tig"
      },
      "source": [
        "## Sieć typu MLP z jedną warstwą ukrytą w problemie MNIST\n",
        "\n",
        "Sprawdzimy jak z problemem MNIST poradzi sobie sieć neuronowa typu MLP z jedną warstwą ukrytą. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9md7fVIkDL2L"
      },
      "source": [
        "### Importy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_LGREjbByfC"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.models import load_model\n",
        "from keras.utils import np_utils\n",
        "\n",
        "#W razie potrzeby zmien aktualny katalog\n",
        "#import os\n",
        "#\n",
        "#path = '.'\n",
        "#os.chdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B7YUblnktrz"
      },
      "source": [
        "### Wczytanie danych\n",
        "Zwróć uwagę, że dane są przechowywane jako 3-wymiarowy tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iMZBv7WDZJm"
      },
      "source": [
        "(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n",
        "print('xtrain.shape',xtrain.shape)\n",
        "print('ytrain.shape',ytrain.shape)\n",
        "print('xtest.shape',xtest.shape)\n",
        "print('ytest.shape',ytest.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xPZCNLQ2zKO"
      },
      "source": [
        "### Inicjalizacja ziarna (aby umożliwić powtarzalność obliczeń)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roJLXMvG4Dgx"
      },
      "source": [
        "seed = 12345\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MRO_hu8E6J6"
      },
      "source": [
        "### Przygotowanie danych wejściowych\n",
        "\n",
        "Oryginalne obrazy 28x28 pikseli będą podawane na warstwę wejściową sieci jako wektory o długości 784.\n",
        "\n",
        "Dodatkowo, pozytywnie na proces uczenia sieci wpłynie normalizacja wartości pikseli z przedziału [0,255] na przedział [0,1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILs4X9XKE-M3"
      },
      "source": [
        "inputs_num = xtrain.shape[1] * xtrain.shape[2] #liczba pikseli = liczba wejsc sieci\n",
        "xtrain = xtrain.reshape(xtrain.shape[0], inputs_num).astype('float32')\n",
        "xtest = xtest.reshape(xtest.shape[0], inputs_num).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "xtrain = xtrain / 255\n",
        "xtest = xtest / 255\n",
        "\n",
        "print(xtrain.shape)\n",
        "print(xtest.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzfgCChvFK2O"
      },
      "source": [
        "### Zakodowanie informacji o klasach (żądane odpowiedzi 10-ciu neuronów wyjściowych)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fX3vi6BFMfk"
      },
      "source": [
        "ytrain = np_utils.to_categorical(ytrain)\n",
        "ytest = np_utils.to_categorical(ytest)\n",
        "num_classes = ytest.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjE0ZCbSFaqJ"
      },
      "source": [
        "### Definiowanie i kompilacja modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae3bOScWFcLT"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(500, input_dim=inputs_num, kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUAOzRYFkELs"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJH9YRq_FlM-"
      },
      "source": [
        "### Zapis do pliku najlepszego modelu\n",
        "\n",
        "Podczas procesu uczenia możemy monitorować wybrane metryki i zapisywać do pliku aktualne modele sieci. Jest to przydatne dla dużych problemów, kiedy nauka sieci trwa bardzo długo i strata wyników w razie awarii jest przykrym doświadczeniem.\n",
        "\n",
        "W poniższym przykładzie monitorujemy jakość klasyfikacji na zbiorze walidacyjnym i zapisujemy do pliku model, o ile jest on lepszy niż jakikolwiek wcześniejszy (tzn. z wcześniejszych epok).\n",
        "\n",
        "__Uwaga__: Warto przed rozpoczęciem uczenia upewnić się, że mamy środowisko z GPU. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPL5cVTFGEj1"
      },
      "source": [
        "logger = keras.callbacks.ModelCheckpoint('mnist_model_MLP.hdf5', monitor='val_accuracy', verbose=0, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVpjux5OICPb"
      },
      "source": [
        "model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=20, batch_size=200, verbose=2, callbacks=[logger])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PefKkDOjJxXq"
      },
      "source": [
        "### Ocena ostatecznego i najlepszego modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0es3VReJ1O-"
      },
      "source": [
        "scores = model.evaluate(xtest, ytest, verbose=0)\n",
        "print(\"Test error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "#Wczytanie najlepszego modelu z pliku\n",
        "model2 = load_model('mnist_model_MLP.hdf5')\n",
        "scores2 = model2.evaluate(xtest, ytest, batch_size=200)\n",
        "print('model z pliku:')\n",
        "print(\"Test error: %.2f%%\" % (100-scores2[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v6MktZ5KLuE"
      },
      "source": [
        "## Najlepsze wyniki dla bazy MNIST \n",
        "\n",
        "Jak otrzymane wyniki mają się do najlepszych?\n",
        "\n",
        "http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryTs2GYGLVBC"
      },
      "source": [
        "## Sieci konwolucyjne\n",
        "\n",
        "Aktualnie, jednymi z najlepszych modeli do analizy obrazów są sieci konwolucyjne.\n",
        "\n",
        "Podstawą ich funkcjonowania są:\n",
        "\n",
        "- warstwy konwolucyjne (współdzielenie wag między neuronami)\n",
        "- warstwy typu MaxPooling (redukcja wymiarowości problemu)\n",
        "- funkcje aktywacji typu ReLU\n",
        "- regularyzacja, np. metodą Dropout\n",
        "\n",
        "Popularnym modelem jest sieć konwolucyjna, w której pewna liczba warstw konwolucyjnych z funkcjami aktywacji ReLU występuje na przemian z warstwami MaxPooling. Po nich następuje jedna lub kilka warstw typu MLP (oznaczenie FC oznacza `Fully Connected`).\n",
        "\n",
        "Często też pojawiają się warstwy implementujące strategie regularyzacji typu Dropout, które mają przeciwdziałać przeuczeniu się modelu.\n",
        "\n",
        "![deep1.png](http://torus.uck.pk.edu.pl/~amarsz/images/deep1.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDmLrJ6aMW_T"
      },
      "source": [
        "### Fukcja aktywacji ReLU\n",
        "\n",
        "https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\n",
        "\n",
        "$$f(x)=x^+=\\max(x,0)$$\n",
        "\n",
        "![deep2.png](http://torus.uck.pk.edu.pl/~amarsz/images/deep2.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS1sDtWgQF_8"
      },
      "source": [
        "### Warstwy konwolucyjne\n",
        "\n",
        "Warstwa konwolucyjna to zestaw filtrów (neuronów), które skanują wszystkie kanały (ang. channels) wejściowego obrazu (trzy w poniższym przykładzie). Skanowanie oznacza, że wagi tego samego neuronu są używane wielokrotnie, co umożliwia ograniczenie liczby potrzebnych neuronów.\n",
        "\n",
        "W poniższym przykładzie są dwa filtry o rozmiarze 3x3, zatem wyjściem tej warstwy konwolucyjnej będzie nowy obraz o dwóch kanałach (Output Volume)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXEQnrbpQfxJ"
      },
      "source": [
        "![deep3.png](http://torus.uck.pk.edu.pl/~amarsz/images/deep3.PNG)\n",
        "![deep4.png](http://torus.uck.pk.edu.pl/~amarsz/images/deep4.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD99qVXXRIbi"
      },
      "source": [
        "### Warstwy Max Pooling\n",
        "\n",
        "Warstwy Max Pooling mają za zadnie ograniczyć wymiarowość danych przekazywanych do kolejnych warstw. Z każdego wybranego obszaru (np. 2x2 piksele) wybierana jest wartość maksymalna. \n",
        "\n",
        "Zwróć uwagę, że pooling nie zmienia \"głębokości\" (liczby kanałów).\n",
        "\n",
        "Przykładowo:\n",
        "\n",
        "![deep5.png](http://torus.uck.pk.edu.pl/~amarsz/images/deep5.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFWk2mRXSJYw"
      },
      "source": [
        "## Realizacja prostej sieci konwolucyjne w bibliotece Keras\n",
        "\n",
        "Projektowana sieć będzie miała tylko jedną warstwę konwolucyjną, po której wystąpi jedna ukryta warstwa typu MLP. Wyjściem całej sieci będzie kolejna warstwa typu `softmax`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwZ-qV3MSP3Q"
      },
      "source": [
        "### Import i wczytanie danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIRkEVJiTD5O"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.models import load_model\n",
        "from keras.utils import np_utils\n",
        "\n",
        "#import os\n",
        "#path = '.'\n",
        "#os.chdir(path)\n",
        "\n",
        "(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n",
        "print('xtrain.shape',xtrain.shape)\n",
        "print('ytrain.shape',ytrain.shape)\n",
        "print('xtest.shape',xtest.shape)\n",
        "print('ytest.shape',ytest.shape)\n",
        "\n",
        "seed = 12345\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLflnd1aTjTC"
      },
      "source": [
        "xtrain = xtrain.reshape(xtrain.shape[0], 28, 28, 1).astype('float32')\n",
        "xtest = xtest.reshape(xtest.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "xtrain = xtrain / 255\n",
        "xtest = xtest / 255\n",
        "\n",
        "# one hot encode outputs\n",
        "ytrain = np_utils.to_categorical(ytrain)\n",
        "ytest = np_utils.to_categorical(ytest)\n",
        "num_classes = ytest.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3fMh3eMTuy-"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu', data_format='channels_last'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttEKDyD4nc0G"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhdwAbP0TrE7"
      },
      "source": [
        "### Trenowanie sieci"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sPoLWiRT6qL"
      },
      "source": [
        "logger = keras.callbacks.ModelCheckpoint('mnist_model_CONV_SIMPLE.hdf5', monitor='val_accuracy', verbose=0, save_best_only=True)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=20, batch_size=200, verbose=2, callbacks=[logger])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS5tqDgWUUnQ"
      },
      "source": [
        "### Testowanie modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l_xBfoVUZ4x"
      },
      "source": [
        "scores = model.evaluate(xtest, ytest, verbose=0)\n",
        "print(\"Test error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "#Best model\n",
        "model2 = load_model('mnist_model_CONV_SIMPLE.hdf5')\n",
        "scores2 = model2.evaluate(xtest, ytest, batch_size=200)\n",
        "print('model z pliku:')\n",
        "print(\"Test error: %.2f%%\" % (100-scores2[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmXCcKTzU--f"
      },
      "source": [
        "## Większa sieć konwolucyjna\n",
        "\n",
        "Porównaj dotychczasowe wyniki z wynikami następującej sieci. Odczytaj jej architekturę."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHY4_GfyVLUd"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.models import load_model\n",
        "from keras.utils import np_utils\n",
        "\n",
        "#import os\n",
        "#path = '.'\n",
        "#os.chdir(path)\n",
        "\n",
        "(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n",
        "print('xtrain.shape',xtrain.shape)\n",
        "print('ytrain.shape',ytrain.shape)\n",
        "print('xtest.shape',xtest.shape)\n",
        "print('ytest.shape',ytest.shape)\n",
        "\n",
        "# fix random seed\n",
        "seed = 12345\n",
        "np.random.seed(seed)\n",
        "\n",
        "\n",
        "xtrain = xtrain.reshape(xtrain.shape[0], 28, 28, 1).astype('float32')\n",
        "xtest = xtest.reshape(xtest.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "xtrain = xtrain / 255\n",
        "xtest = xtest / 255\n",
        "\n",
        "# one hot encode outputs\n",
        "ytrain = np_utils.to_categorical(ytrain)\n",
        "ytest = np_utils.to_categorical(ytest)\n",
        "num_classes = ytest.shape[1]\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(15, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "logger = keras.callbacks.ModelCheckpoint('mnist_model_CONV_BIGGER.hdf5', monitor='val_accuracy', verbose=0, save_best_only=True)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=20, batch_size=200, verbose=2, callbacks=[logger])\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(xtest, ytest, verbose=0)\n",
        "print(\"Test error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "#Best model\n",
        "model2 = load_model('mnist_model_CONV_BIGGER.hdf5')\n",
        "scores2 = model2.evaluate(xtest, ytest, batch_size=200)\n",
        "print('model z pliku:')\n",
        "print(\"Test error: %.2f%%\" % (100-scores2[1]*100))\n",
        "\n",
        "print('end')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSyfS6gsVnjB"
      },
      "source": [
        "## Porównanie modeli"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChKIJ_ZX2EDf"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.models import load_model\n",
        "from keras.utils import np_utils\n",
        "\n",
        "#import os\n",
        "#path = '.'\n",
        "#os.chdir(path)\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)\n",
        "\n",
        "(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n",
        "print('xtrain.shape',xtrain.shape)\n",
        "print('ytrain.shape',ytrain.shape)\n",
        "print('xtest.shape',xtest.shape)\n",
        "print('ytest.shape',ytest.shape)\n",
        "\n",
        "xtrain = xtrain.reshape(xtrain.shape[0], 784).astype('float32')\n",
        "xtest = xtest.reshape(xtest.shape[0], 784).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "xtrain = xtrain / 255\n",
        "xtest = xtest / 255\n",
        "\n",
        "# one hot encode outputs\n",
        "ytrain = np_utils.to_categorical(ytrain)\n",
        "ytest = np_utils.to_categorical(ytest)\n",
        "\n",
        "#Porownanie sieci\n",
        "\n",
        "#Siec MLP\n",
        "model = load_model('mnist_model_MLP.hdf5')\n",
        "scores = model.evaluate(xtest, ytest, batch_size=200)\n",
        "print(\"Test error (Model MLP): %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "\n",
        "xtrain = xtrain.reshape(xtrain.shape[0], 28, 28, 1).astype('float32')\n",
        "xtest = xtest.reshape(xtest.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "#Siec konwolucyjna mala\n",
        "model = load_model('mnist_model_CONV_SIMPLE.hdf5')\n",
        "scores = model.evaluate(xtest, ytest, batch_size=200)\n",
        "print(\"Test error (Model CONV SIMPLE): %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "#Siec konwolucyjna wieksza\n",
        "model = load_model('mnist_model_CONV_BIGGER.hdf5')\n",
        "scores = model.evaluate(xtest, ytest, batch_size=200)\n",
        "print(\"Test error (Model CONV BIGGER): %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "print('end')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C57dALyNj4Se"
      },
      "source": [
        "&copy; Katedra Informatyki, Politechnika Krakowska"
      ]
    }
  ]
}